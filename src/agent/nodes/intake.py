"""
Architect Agent - Intake Node
==============================
First node in the workflow. Collects initial project requirements
and generates clarifying questions.
"""
import logging
from typing import Tuple

from ..state import (
    ProjectContext, Requirement, Constraint, IntakeResponse,
    Priority
)
from ...llm.client import LLMClient
from ...llm.prompts import INTAKE_PROMPT, BASE_SYSTEM_PROMPT

logger = logging.getLogger(__name__)


async def intake_node(
    ctx: ProjectContext,
    llm: LLMClient
) -> Tuple[ProjectContext, str]:
    """
    Intake node - analyzes initial user message and extracts structured info.

    Args:
        ctx: Current project context
        llm: LLM client instance

    Returns:
        Tuple of (updated context, reply message)
    """
    logger.info(f"[{ctx.session_id}] Running intake node")

    # Build prompt
    history_str = _format_history(ctx.conversation_history)
    prompt = INTAKE_PROMPT.format(
        user_message=ctx.initial_summary or "",
        history=history_str if history_str else "××™×Ÿ ×”×™×¡×˜×•×¨×™×” ×§×•×“×ž×ª"
    )

    # Call LLM for structured response
    try:
        response = await llm.generate_structured(
            prompt=prompt,
            response_model=IntakeResponse,
            system_prompt=BASE_SYSTEM_PROMPT
        )

        # Update context
        ctx.project_name = response.project_name
        ctx.requirements.extend(response.requirements)
        ctx.constraints.extend(response.constraints)
        ctx.open_questions = response.questions[:5]  # Max 5 questions
        ctx.confidence_score = response.confidence
        ctx.current_node = "intake"

        # Build reply
        reply = _build_intake_reply(response)
        ctx.add_message("assistant", reply)

        logger.info(
            f"[{ctx.session_id}] Intake complete: "
            f"{len(ctx.requirements)} requirements, "
            f"{len(ctx.constraints)} constraints, "
            f"confidence: {ctx.confidence_score:.2f}"
        )

        return ctx, reply

    except Exception as e:
        logger.error(f"[{ctx.session_id}] Intake node failed: {e}")
        ctx.error_message = str(e)

        # Fallback: ask for clarification
        reply = """
## ðŸ¤” ×¦×¨×™×š ×§×¦×ª ×™×•×ª×¨ ×ž×™×“×¢

×œ× ×”×¦×œ×—×ª×™ ×œ× ×ª×— ××ª ×”×ª×™××•×¨ ×‘×ž×œ×•××•. ×‘×‘×§×©×” ×¡×¤×¨ ×œ×™:

1. ×ž×” ×”×ž×•×¦×¨/×©×™×¨×•×ª ×©××ª×” ×‘×•× ×”?
2. ×ž×™ ×§×”×œ ×”×™×¢×“?
3. ×ž×” ×”×¡×“×¨ ×’×•×“×œ ×”×¦×¤×•×™? (×ž×©×ª×ž×©×™×, ×ª× ×•×¢×”)
4. ×™×© ×œ×•×— ×–×ž× ×™× ××• ×ª×§×¦×™×‘ ×ž×•×’×“×¨?
5. ×™×© ×“×¨×™×©×•×ª ×˜×›× ×•×œ×•×’×™×•×ª ×ž×™×•×—×“×•×ª?
"""
        ctx.add_message("assistant", reply)
        ctx.open_questions = [
            "×ž×” ×”×ž×•×¦×¨/×©×™×¨×•×ª?",
            "×ž×™ ×§×”×œ ×”×™×¢×“?",
            "×¡×“×¨ ×’×•×“×œ ×¦×¤×•×™?",
            "×œ×•×— ×–×ž× ×™×/×ª×§×¦×™×‘?"
        ]

        return ctx, reply


def _format_history(history: list) -> str:
    """Format conversation history for prompt."""
    if not history:
        return ""

    formatted = []
    for msg in history[-10:]:  # Last 10 messages
        role = msg.get("role", "user")
        content = msg.get("content", "")
        formatted.append(f"{role}: {content}")

    return "\n".join(formatted)


def _build_intake_reply(response: IntakeResponse) -> str:
    """Build a user-friendly reply from intake response."""
    parts = [
        f"## ðŸ“Š ×”×‘× ×ª×™ - {response.project_name}\n",
        response.summary,
        ""
    ]

    # Show identified requirements summary
    if response.requirements:
        func_reqs = [r for r in response.requirements if r.category == "functional"]
        non_func_reqs = [r for r in response.requirements if r.category == "non_functional"]

        if func_reqs:
            parts.append(f"**×“×¨×™×©×•×ª ×¤×•× ×§×¦×™×•× ×œ×™×•×ª:** ×–×™×”×™×ª×™ {len(func_reqs)} ×“×¨×™×©×•×ª")
        if non_func_reqs:
            parts.append(f"**×“×¨×™×©×•×ª ×œ×-×¤×•× ×§×¦×™×•× ×œ×™×•×ª:** ×–×™×”×™×ª×™ {len(non_func_reqs)} ×“×¨×™×©×•×ª")
        parts.append("")

    # Show constraints if any
    if response.constraints:
        parts.append(f"**××™×œ×•×¦×™× ×©×–×™×”×™×ª×™:** {len(response.constraints)}")
        for c in response.constraints[:3]:  # Show first 3
            severity_icon = {
                Priority.CRITICAL: "ðŸ”´",
                Priority.HIGH: "ðŸŸ ",
                Priority.MEDIUM: "ðŸŸ¡",
                Priority.LOW: "ðŸŸ¢"
            }.get(c.severity, "âšª")
            parts.append(f"  {severity_icon} {c.description}")
        parts.append("")

    # Add questions
    if response.questions:
        parts.append("### â“ ×©××œ×•×ª ×œ×”×‘×”×¨×”:\n")
        for i, q in enumerate(response.questions[:5], 1):
            parts.append(f"{i}. {q}")

    # Add confidence indicator
    confidence_text = _get_confidence_text(response.confidence)
    parts.append(f"\n*×¨×ž×ª ×”×‘× ×”: {confidence_text}*")

    return "\n".join(parts)


def _get_confidence_text(confidence: float) -> str:
    """Get Hebrew text for confidence level."""
    if confidence >= 0.8:
        return "×’×‘×•×”×” âœ…"
    elif confidence >= 0.6:
        return "×˜×•×‘×” ðŸ‘"
    elif confidence >= 0.4:
        return "×‘×™× ×•× ×™×ª - ×¦×¨×™×š ×¢×•×“ ×ž×™×“×¢"
    else:
        return "× ×ž×•×›×” - ×¦×¨×™×š ×”×¨×‘×” ×™×•×ª×¨ ×ž×™×“×¢"
